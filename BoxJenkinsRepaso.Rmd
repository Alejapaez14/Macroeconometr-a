---
title: "Box - Jenkins. Repaso 2"
author: "Macroeconometría"
output: html_notebook
---
# FASES DE LA METODOLOGÍA BOX-JENKINS

- 1. Identificación (estabilización de varianza, estabilización de nivel, identificación de los órdenes p,d,q)
- 2. Estimación
- 3. Verificación de supuestos
- 4. Uso del modelo, por ejemplo: pronóstico

# 1. Identificación: estabilización de varianza
Con el fin de estabilizar la varianza de una serie $Z_{t}$ se elige la potencia $\lambda$ de tal forma que se cumpla la siguiente relación:


## 1.1 Identificación: Estabilización de varianza (Metodología de Guerrero)
$$
\dfrac{\sigma_{t}}{\mu_{t}^{1-\lambda}}= \mbox{constante}, \qquad{\forall t=1,2,\dots, T}
$$

Dado que para cada momento del tiempo ($t$) solo se tiene una única observación de $Z_{t}$ no es posible encontrar una estimación de $\sigma_{t}$ . Guerrero (1993) propone el esquema de operalización del método:

Dividir las $T$ observaciones en $H$ grupos que contengan $R=\frac{T-n}{H}$ observaciones contiguas, dejando fuera $n$ observaciones ya sean del principio o del final de la serie, se debe tratar de tener homogeneidad entre los grupos y que además contengan el  mismo  número de observaciones.

Cada grupo tendrá una media dada por

$$
\bar{Z_{h}}=\dfrac{\sum_{r=1}^{R}Z_{h,r}}{R},
$$

con $Z_{h,r}$ siendo la $r$-ésima observación del grupo $h$; y una desviación estándar 

$$
S_{h}=\sqrt{\dfrac{\sum_{r=1}^{R}\left(Z_{h,r}-\bar{Z}_{h}\right)^{2}}{R-1}}
$$

Para un $\lambda$ particular se define su coeficiente de variación 
$$
CV(\lambda)=\dfrac{SD(\lambda)}{M(\lambda)}, \mbox{ con }\\ M(\lambda)=\dfrac{\sum_{h=1}^{H}\left(\dfrac{S_{h}}{\bar{Z}_{h}^{1-\lambda}}\right)}{H}, \quad SD(\lambda)=\sqrt{\dfrac{\sum_{h=1}^{H}\left[\left(\dfrac{S_{h}}{\bar{Z}_{h}^{1-\lambda}}\right)- M(\lambda)\right]^{2}}{H-1}}
$$

*Se debe elegir la potencia que proporciona el mínimo coeficiente de variación.*
```{r}
#install.packages("forecast")
library(forecast)
lamda=BoxCox.lambda(serie, method = c("guerrero"), lower = -1, upper = 1)
lamda
```


$$
G(Z_{t})=\begin{cases}
Z_{t}^{\lambda} & \lambda \ne 0 \\
\ln(Z_{t}) & \lambda=0
\end{cases}
$$


## 1.2 Identificación: Estabilización de nivel

Dadas las posibles diferencias de la serie transformada en varianza ($\nabla G(Z_{t})=G(Z_{t})-G(Z_{t-1})$), se elige aquella para la cual se minimice el estadístico (Anderson 1976):
$$
S^2(j)=\dfrac{1}{N-j-1}\sum_{t=j+1}^{T}\left[\nabla^{j}G(Z_{t})-\sum_{t=j+1} ^{T}\dfrac{\nabla^{j}G(Z_{t})}{T-j} \right]^{2}
$$

Otra herramienta de identificación es el comportamiento de la ACF y la PACF. Más adelante se trtatarán las pruebas sobre existencia de raíz unitaria.

```{r}
serieest
```

## 1.3 Identificación: Órdenes p,q del ARMA

### 1.3.1 Si el proceso es AR(p)
Quenouille (1949) mostró que si el proceso generador es un AR(p) las autocorrelaciones parciales se distribuyen de manera independiente con

$$
E(\hat{\phi}_{ii})=\phi_{ii}\\
VAR(\hat{\phi}_{ii})\approx \dfrac{1}{T-d}, \forall i>p.
$$
Con esto se puede concluir que, $\phi_{ii} \ne 0$ si $\hat{\phi}_{ii}$ se encuentra fuera del intervalo
$$
\pm 2 \sqrt{VAR(\hat{\phi}_{ii})}\approx \dfrac{2}{\sqrt{T-d}}, \forall i > p.
$$

### 1.3.2 Si el proceso es MA(q)
Se prueba iterativamente el orden del proceso, empezando por $q=1$, luego $q=2$, y así sucesivamente. Para un determinado orden $q$ se prueba si las autocorrelaciones de orden superior a $q$ son estadísticamente iguales a cero. para ello se considera la varianza de dichas autocorrelaciones:

$$
VAR(\hat{\rho_{k}})=\dfrac{1}{T-d}\left(1+2\sum_{j=1}^{q} \hat{\rho_{j}}^2\right), \forall k>q
$$
Con un número grande de observaciones, los límites para determinar las autocorrelaciones significativas están dadas por

$$
estimador \pm 1.96 \times \mbox{Desviación estandar},
$$
que en la práctica, comúnmente se evalúa mediante la comprobación de la condición

$$
|\hat{\rho}_{k}|>2 \sqrt{\dfrac{1}{T-d}\left(1+2\sum_{j=1}^{q} \hat{\rho_{j}}^2\right)}, \forall k>q
$$
en cuyo caso se concluye que dicha autocorrelación de orden $k$ es diferente de cero.


# 2 Estimación: comando ARIMA
La estimación se realiza con aproximaciones que maximizan la verosimilitud del proceso.

```{r}
# Ejemplo de comando para estimar un ARMA (1,3)
modelo1 <- arima(serieest, order = c(1,0,3), method = c("ML"))
modelo1

# RExtracción de los residuales estimados del modelo
residuales1=modelo1$residuals


# Un comando directo que apoya la identificación del modelo con otros criterios
# Averiguar sobre criterios de información antes de usar:
?auto.arima
auto.arima(serieesst)
```



# 3 Verificación de supuestos

# Supuesto 1: media cero de residuales
$$
m(\hat{a})=\dfrac{\sum_{t=t'}^{T}\hat{a}_{t}}{T-d-p}\\
\hat{\sigma}_{a}=\sqrt{\dfrac{\sum_{t=t'}^{T}(\hat{a}_{t}-m(\hat{a}))^2}{T-d-p-q}} \quad \mbox{donde } t'=d+p+1
$$

Si $H_{0}:$ la media de $\lbrace a_{t}\rbrace$ es igual a 0\\
$H_{a}:$ Violación del supuesto de media cero

$$
\displaystyle\left\lvert \dfrac{\sqrt{T-d-p}\quad m(\hat{a})}{\hat{\sigma}_{a}}\right\rvert <2 \implies \mbox{No existe evidencia para rechazar }  H_{0}
$$

El rechazo de $H_{0}$ implica que existe una parte determinística en $\lbrace \hat{a}_{t} \rbrace$  que no se ha sido considerada en el modelo y se requiere de la inclusión de una tendencia determinista $\theta_{0}$.
El valor inicial para dicha tendencia determinista está dado por $m(\hat{a}_{t})$.
En algunas ocasiones, antes de incluir el parámetro $\theta_0$ podría considerarse la inclusión de un término autoregresivo o una diferencia adicional.


## Supuesto 2: varianza constante de los residuales

En este punto se sugiere inspección visual de la gráfica de los residuos vs. tiempo. El punto central es que solo violaciones muy notorias podrían causar problema.
Corrección: Aplicar transformación de potencia, tener en cuenta  Box-Cox (Revisar fase de estabilización de varianza).

## Supuesto 3: Independencia de los residuales (ruido blanco)
Dado que independencia implica no autocorrelación se debe satisfacer: 

$$
\rho_{k}(a)=0 \quad \forall k \ne 0
$$
Para esto se emplea el siguiente estimador de las autocorrelaciones de los residuales

$$
\hat{\rho}_{k}(\hat{a})=\dfrac{\sum_{t}^{T-k}\hat{a}_{t}\hat{a}_{t+k}}{\sum_{t}^{T}\hat{a}_{t}^{2}}, \quad k=1,2,3, \dots
$$
Si el test indica que lasautocorrelaciones no corresponden a un proceso ruido blanco ,es de suponer que corresponden a un proceso ARMA, el cual sugerirá modificaciones al modelo original. 


Pruebas de significancia conjunta (tipo Pormanteau) de K autocorrelaciones simultáneas.

$$
\mbox{Q de Box-Pierce:} \quad Q=(T-d-p) \sum_{k=1}^{K}(\hat{\rho}_{k}(\hat{a}))^{2} \sim \chi ^{2}(K-p-q)\\
\mbox{Q' de Ljung-Box:} \quad Q'=(T-d-p)(T-d-p+2) \sum_{k=1}^{K}\dfrac{(\hat{\rho}_{k}(\hat{a}))^{2}}{T-d-p-k} \sim \chi ^{2}(K-p-q) \\
$$

```{r}
Box.test(residuales1, type = c("Box-Pierce"))
Box.test(residuales1, type = c("Ljung-Box"))
```

Si el test indica que las autocorrelaciones no corresponden a un proceso ruido blanco, es de suponer que corresponden a un proceso ARMA, el cual debe ser identificado sobre los $\hat{a}_{t}$ . Este sugerirá modificaciones al modelo original identificado.



## Supuesto 4: Normalidad
El supuesto de normalidad es sobre  $a_{t}$  y no tiene que ser exactamente satisfecho por $\hat{a}_{t}$. Pequeñas violaciones son aceptadas. Si el problema es notorio, podría pensarse en transformaciones de potencia.

- Procedimiento 1: En una distribución normal, aproximadamente el 95% de las observaciones deben estar dentro de un intervalo que se extienda por encima y por debajo de la media dos desviaciones Estándar. Así. si la media de los residuos es cero, a lo  más un total de $\dfrac{T-d-p}{20}$ observaciones estarán por fuera del intervalo   $\left( -2 \hat{\sigma}_{a}, 2 \hat{\sigma}_{a}\right)$


- Procedimiento 2: test de Jarque-Bera


## Supuesto 5: No existencia de observaciones aberrantes
La gráfica de los residuos vs. tiempo permite visualizar observaciones anómalas.

Un residuo que se encuentra por fuera del intervalo  $\left( -3 \hat{\sigma}_{a}, 3 \hat{\sigma}_{a}\right)$ implica que sucedió un evento con una probabilidad muy pequeña o que el residuo corresponde a una observación que no fue generada por el mismo proceso generador de datos.

No se debe descartar que se haya dado en realidad un evento altamente improbable y se debe investigar su causa. El ajuste de la observación puede causar problemas ya que podría haberse dado un cambio causado por una intervención y esta debería ser incluida en el modelo.




## Supuesto 6: Parsimonia
El concepto de parsimonia implica que no se puede reducir el número de parámteros involucrados en el modelo, es decir     que todos son necesarios para explicar el comportamiento de la serie y no pueden ser considerados cero.

Construcción para cada parámetro de un intervalos al 95% de confianza:
$$
\left(\hat{\delta}-2\sqrt{\hat{VAR}(\hat{\delta})}, \hat{\delta}+2\sqrt{\hat{VAR}(\hat{\delta})}\right), \quad  \delta = \lbrace \theta, \phi \rbrace
$$
Corrección: Si el parámetro no es significativo  se debe excluir su rezago correspondiente en el modelo ya sea en la parte autorregresiva o en la parte de media móvil  y volver a estimar.



# 4 Uso del modelo
## 4.1 Pronóstico

```{r}

# Pronóstico
forecast(modelo1, h=3)
plot(forecast(object = modelo1,h = 3))

# INVESTIGAR: ¿Cómo se crean los intervalos de confianza del pronóstico del modelo?
```


##4.2 Impulso respuesta